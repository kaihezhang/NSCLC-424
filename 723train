import os
import re
import json
import torch
import torch.nn.functional as F
import pandas as pd
import numpy as np
import nibabel as nib
from PIL import Image
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader, Dataset
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import f_regression
from sklearn.decomposition import PCA
from model import RNAEncoder, ResNetMultiChannel, CLIPModel, ContrastiveLoss,LightRNATransformer,ViTMultiChannel,ImprovedRNAEncoder


rna_path = r'C:\Users\95602\Desktop\ultrasound-contrastivemodels-klr-us-rna\TCIA\TCIA\combined_summary_filtered.csv'
image_directory = r'C:\Users\95602\Desktop\ultrasound-contrastivemodels-klr-us-rna\TCIA\TCIA'
bbox_json_path = r'C:\Users\95602\PycharmProjects\PythonProject2\bbox_coords.json'
SAVE_DIR = r'C:\Users\95602\Desktop\ultrasound-contrastivemodels-klr-us-rna\TCIA\TCIA'
N_CHANNELS = 16
IMG_SIZE = 224
EPOCHS = 100
BATCH_SIZE = 4
EMBEDDING_DIM = 256  

os.makedirs(SAVE_DIR, exist_ok=True)

print("Step 1: è¯»å–RNAæ•°æ®...")
rna_df = pd.read_csv(rna_path, index_col=0)
rna_df = rna_df.fillna(0).T
rna_df.index = rna_df.index.str.strip()
print(f"åŸå§‹RNAæ•°æ®å½¢çŠ¶: {rna_df.shape}")


print("ğŸ“Š Step 2: Linear Regressionç‰¹å¾ç­›é€‰ (p<0.01) + PCAé™ç»´80%...")
if 'CD274' not in rna_df.columns:
    raise ValueError('CD274 not found in RNA matrix columns!')

y = rna_df['CD274'].values
X = rna_df.values
genes = np.array(rna_df.columns)
cd274_idx = np.where(genes == 'CD274')[0][0]
X_for_select = np.delete(X, cd274_idx, axis=1)
genes_for_select = np.delete(genes, cd274_idx)

F_stat, pvals = f_regression(X_for_select, y)
selected = pvals < 0.01
print(f"é€šè¿‡p<0.01ç­›é€‰ï¼Œå‰©ä½™åŸºå› æ•°: {selected.sum()}")
if selected.sum() == 0:
    raise ValueError("No gene passed p<0.01, please check your data!")

# ğŸ¯ Step 2.1: ä¿ç•™ç­›é€‰åçš„åŸºå› å¹¶æ ‡å‡†åŒ–
X_selected = X_for_select[:, selected]
genes_selected = genes_for_select[selected]
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_selected)
print(f"æ ‡å‡†åŒ–åå½¢çŠ¶: {X_scaled.shape}")

# ğŸ¯ Step 2.2: PCAé™ç»´åˆ°80%æ–¹å·®
pca = PCA(n_components=0.95, random_state=42)  # ä¿ç•™80%æ–¹å·®
X_pca = pca.fit_transform(X_scaled)
print(f"PCAé™ç»´åå½¢çŠ¶: {X_pca.shape}")
print(f"PCAè§£é‡Šçš„æ–¹å·®æ¯”ä¾‹: {pca.explained_variance_ratio_.sum():.3f}")
print(f"PCAæˆåˆ†æ•°: {pca.n_components_}")


rna_df_filtered = pd.DataFrame(X_pca, index=rna_df.index)
print(f"æœ€ç»ˆRNAç‰¹å¾ç»´åº¦: {rna_df_filtered.shape}")


print("ğŸ“Š Step 3: åŒ¹é…å›¾åƒå’ŒRNAæ ·æœ¬...")
with open(bbox_json_path, 'r') as f:
    bbox_coords = json.load(f)
nifti_files = []
for root, _, files in os.walk(image_directory):
    for fname in files:
        if fname.lower().endswith('.nii') or fname.lower().endswith('.nii.gz'):
            nifti_files.append(os.path.join(root, fname))
rna_samples, image_paths = [], []
matched_count = 0
for sample_id in rna_df_filtered.index:
    matches = [p for p in nifti_files if os.path.basename(p) in (f"{sample_id}.nii.gz", f"{sample_id}.nii")]
    if not matches:
        continue
    img_path = matches[0]
    seg_key = 'seg' + sample_id.replace('-', '') + '.nii.gz'
    if seg_key not in bbox_coords:
        continue
    rna_samples.append(rna_df_filtered.loc[sample_id])
    image_paths.append(img_path)
    matched_count += 1
if not rna_samples:
    raise ValueError("æœªåŒ¹é…åˆ°ä»»ä½•æ ·æœ¬ï¼")
rna_df_filtered = pd.DataFrame(rna_samples)
print(f"æˆåŠŸåŒ¹é… {matched_count} ä¸ªæ ·æœ¬ç”¨äºè®­ç»ƒ/éªŒè¯")


rna_train, rna_val, img_train_paths, img_val_paths = train_test_split(
    rna_df_filtered, image_paths, test_size=0.2, random_state=42
)



def strip_nii_suffix(filename):
    return re.sub(r'(\.nii(\.gz)?)$', '', filename)


def sample_slices(total_slices, n=N_CHANNELS):
    if total_slices < n:
        idxs = list(range(total_slices)) + [total_slices // 2] * (n - total_slices)
        return idxs[:n]
    else:
        return np.linspace(0, total_slices - 1, n, dtype=int)


class SimpleRNACustomDataset(Dataset):
    

    def __init__(self, rna_data, img_paths, bbox_path, img_size=IMG_SIZE, n_channels=N_CHANNELS):
        self.rna = rna_data.reset_index(drop=True)
        self.img_paths = img_paths
        with open(bbox_path, 'r') as f:
            self.bbox = json.load(f)
        self.img_size = img_size
        self.n_channels = n_channels

        print(f"Datasetåˆå§‹åŒ–: {len(self.img_paths)} ä¸ªæ ·æœ¬ï¼ˆæ— æ•°æ®å¢å¼ºï¼‰")

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        try:
            rna_vec = torch.tensor(self.rna.iloc[idx].values, dtype=torch.float)
            path = self.img_paths[idx]
            vol = nib.load(path).get_fdata()
            fname = os.path.basename(path)
            sample_id_core = strip_nii_suffix(fname)
            seg_key = 'seg' + sample_id_core.replace('-', '') + '.nii.gz'

            if seg_key not in self.bbox:
                raise KeyError(f"æœªæ‰¾åˆ°åˆ†å‰²åæ ‡ï¼š{seg_key}")

            bbox = self.bbox[seg_key]
            x0, x1 = sorted((bbox['x_min'], bbox['x_max']))
            y0, y1 = sorted((bbox['y_min'], bbox['y_max']))
            z0, z1 = sorted((bbox['z_min'], bbox['z_max']))
            roi = vol[x0:x1, y0:y1, z0:z1]

            if roi.shape[2] == 0:
                raise ValueError(f"ç©º ROI: {fname}")

            # ç›´æ¥æ ‡å‡†åŒ–ROIï¼Œä¸ä½¿ç”¨æ•°æ®å¢å¼º
            roi = (roi - roi.min()) / (roi.max() - roi.min() + 1e-8)

            # é‡‡æ ·åˆ‡ç‰‡å¹¶è°ƒæ•´å¤§å°
            slice_idxs = sample_slices(roi.shape[2], n=self.n_channels)
            imgs = [roi[:, :, i] for i in slice_idxs]
            imgs = np.stack(imgs, axis=0)

            # è°ƒæ•´å›¾åƒå¤§å°
            imgs_resized = []
            for i in range(self.n_channels):
                img = Image.fromarray((imgs[i] * 255).astype(np.uint8))
                img = img.resize((self.img_size, self.img_size))
                imgs_resized.append(np.array(img, dtype=np.float32) / 255.0)

            imgs_resized = np.stack(imgs_resized, axis=0)
            imgs_tensor = torch.tensor(imgs_resized, dtype=torch.float)

            return rna_vec, imgs_tensor

        except Exception as e:
            print(f"å¤„ç†æ ·æœ¬ {idx} æ—¶å‡ºé”™: {e}")
            rna_vec = torch.zeros(self.rna.shape[1], dtype=torch.float)
            imgs_tensor = torch.zeros(self.n_channels, self.img_size, self.img_size, dtype=torch.float)
            return rna_vec, imgs_tensor



train_ds = SimpleRNACustomDataset(rna_train, img_train_paths, bbox_json_path)
val_ds = SimpleRNACustomDataset(rna_val, img_val_paths, bbox_json_path)

train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

input_dim = rna_df_filtered.shape[1]
print(f"RNAç¼–ç å™¨è¾“å…¥ç»´åº¦: {input_dim}")
print(f"åµŒå…¥ç»´åº¦: {EMBEDDING_DIM}")


model = CLIPModel(
    ImprovedRNAEncoder(input_dim=input_dim, embedding_dim=EMBEDDING_DIM),
    ResNetMultiChannel(n_channels=N_CHANNELS, embedding_dim=EMBEDDING_DIM)
).to(device)

criterion = ContrastiveLoss(temperature=0.5)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer,
    mode='min',           
    factor=0.5,          
    patience=10,         
    verbose=True,        
    min_lr=1e-7,        
    threshold=1e-4       
)


class ImprovedEarlyStopping:
    def __init__(self, patience=25, min_delta=1e-3):
        self.patience = patience
        self.min_delta = min_delta
        self.best_loss = np.inf
        self.counter = 0
        self.best_weights = None

    def __call__(self, loss, model):
        if loss < self.best_loss - self.min_delta:
            self.best_loss = loss
            self.counter = 0
            self.best_weights = model.state_dict().copy()
        else:
            self.counter += 1

        if self.counter >= self.patience:
            if self.best_weights:
                model.load_state_dict(self.best_weights)
            return True
        return False


early_stop = ImprovedEarlyStopping()


def compute_similarity_metrics(model, data_loader, device):
    
    model.eval()
    all_rna_emb, all_img_emb = [], []

    with torch.no_grad():
        for rna_vec, imgs in data_loader:
            rna_vec, imgs = rna_vec.to(device), imgs.to(device)
            rna_emb, img_emb = model(rna_vec, imgs)
            all_rna_emb.append(rna_emb.cpu())
            all_img_emb.append(img_emb.cpu())

    all_rna_emb = torch.cat(all_rna_emb, dim=0)
    all_img_emb = torch.cat(all_img_emb, dim=0)

    similarity_matrix = torch.matmul(
        F.normalize(all_rna_emb, p=2, dim=-1),
        F.normalize(all_img_emb, p=2, dim=-1).T
    )

    _, predicted = similarity_matrix.max(1)
    labels = torch.arange(len(all_rna_emb))
    accuracy = (predicted == labels).float().mean().item()
    diagonal_sim = similarity_matrix.diag().mean().item()

    return accuracy, diagonal_sim



print("å¼€å§‹è®­ç»ƒ...")
print(f"é…ç½®: RNAç‰¹å¾={input_dim}ç»´, åµŒå…¥={EMBEDDING_DIM}ç»´")
best_val_loss = float('inf')
best_model_state = None

for epoch in range(1, EPOCHS + 1):
    # è®­ç»ƒé˜¶æ®µ
    model.train()
    train_loss, train_batches = 0.0, 0

    for batch_idx, (rna_vec, imgs) in enumerate(train_loader):
        rna_vec, imgs = rna_vec.to(device), imgs.to(device)

        emb_r, emb_i = model(rna_vec, imgs)
        loss = criterion(emb_r, emb_i)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        train_batches += 1

        if batch_idx == 0:
            print(f"  Epoch {epoch:2d} Batch {batch_idx}: Loss={loss.item():.4f}")

    train_loss /= max(train_batches, 1)

    # éªŒè¯é˜¶æ®µ
    model.eval()
    val_loss, val_batches = 0.0, 0

    with torch.no_grad():
        for rna_vec, imgs in val_loader:
            rna_vec, imgs = rna_vec.to(device), imgs.to(device)
            emb_r, emb_i = model(rna_vec, imgs)
            loss = criterion(emb_r, emb_i)
            val_loss += loss.item()
            val_batches += 1

    val_loss /= max(val_batches, 1)


    scheduler.step(val_loss)
    current_lr = optimizer.param_groups[0]['lr']

    print(f"Epoch {epoch:2d}: Train_Loss={train_loss:.4f} | Val_Loss={val_loss:.4f} | LR={current_lr:.6f}")

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        best_model_state = model.state_dict().copy()
        print(f"  æ–°çš„æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")

    if early_stop(val_loss, model):
        print("EarlyStopping triggered.")
        break

final_model_path = os.path.join(SAVE_DIR, "7615best_clip_lrp01_pca80_512d_no_augment.pth")
torch.save(best_model_state, final_model_path)
print(f"ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ°: {final_model_path}")


print("\nğŸ“Š æœ€ç»ˆè¯„ä¼°:")
model.load_state_dict(best_model_state)
final_train_acc, final_train_sim = compute_similarity_metrics(model, train_loader, device)
final_val_acc, final_val_sim = compute_similarity_metrics(model, val_loader, device)

